{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uproot as uproot\n",
    "import uproot3 as uproot3\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_vars = [\n",
    "    \"nue_score\",\n",
    "    \"numu_score\",\n",
    "    \"numu_cc_flag\"\n",
    "]\n",
    "\n",
    "eval_vars = [\n",
    "    \"run\",\n",
    "    \"subrun\",\n",
    "    \"event\",\n",
    "    \"truth_nuEnergy\",\n",
    "    \"truth_nuPdg\",\n",
    "    \"truth_isCC\",\n",
    "    \"truth_vtxInside\",\n",
    "    \"match_isFC\",\n",
    "    \"match_completeness_energy\",\n",
    "    \"truth_energyInside\",\n",
    "\n",
    "    \"weight_cv\",\n",
    "    \"weight_spline\",\n",
    "]\n",
    "\n",
    "eval_data_vars = [\n",
    "    \"match_isFC\",\n",
    "]\n",
    "\n",
    "kine_vars = [\n",
    "    \"kine_reco_Enu\",\n",
    "]\n",
    "\n",
    "pf_vars = [\n",
    "    \"reco_muonMomentum\",\n",
    "    \"truth_muonMomentum\",\n",
    "    \"truth_nuIntType\",\n",
    "    \"truth_nuScatType\",\n",
    "]\n",
    "\n",
    "pf_data_vars = [\n",
    "    \"reco_muonMomentum\",\n",
    "]\n",
    "\n",
    "\n",
    "loc = \"/Users/leehagaman/data/from_london/\"\n",
    "\n",
    "f = uproot3.open(loc + \"checkout_prodgenie_bnb_nu_overlay_run1.root\")[\"wcpselection\"]\n",
    "f_bdt = f[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_eval = f[\"T_eval\"].pandas.df(eval_vars, flatten=False)\n",
    "f_kine = f[\"T_KINEvars\"].pandas.df(kine_vars, flatten=False)\n",
    "f_pfeval = f[\"T_PFeval\"].pandas.df(pf_vars, flatten=False)\n",
    "nu_overlay_run1_pot = np.sum(f[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)[\"pot_tor875good\"].to_numpy())\n",
    "nu_overlay_run1_df = pd.concat([f_bdt, f_eval, f_kine, f_pfeval], axis=1, sort=False)\n",
    "nu_overlay_run1_df[\"file\"] = \"nu_overlay_run1\"\n",
    "del f\n",
    "del f_bdt\n",
    "del f_eval\n",
    "del f_kine\n",
    "del f_pfeval\n",
    "\n",
    "f = uproot3.open(loc + \"checkout_prodgenie_bnb_nu_overlay_run2.root\")[\"wcpselection\"]\n",
    "f_bdt = f[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_eval = f[\"T_eval\"].pandas.df(eval_vars, flatten=False)\n",
    "f_kine = f[\"T_KINEvars\"].pandas.df(kine_vars, flatten=False)\n",
    "f_pfeval = f[\"T_PFeval\"].pandas.df(pf_vars, flatten=False)\n",
    "nu_overlay_run2_pot = np.sum(f[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)[\"pot_tor875good\"].to_numpy())\n",
    "nu_overlay_run2_df = pd.concat([f_bdt, f_eval, f_kine, f_pfeval], axis=1, sort=False)\n",
    "nu_overlay_run2_df[\"file\"] = \"nu_overlay_run2\"\n",
    "del f\n",
    "del f_bdt\n",
    "del f_eval\n",
    "del f_kine\n",
    "del f_pfeval\n",
    "\n",
    "f = uproot3.open(loc + \"checkout_prodgenie_bnb_nu_overlay_run3.root\")[\"wcpselection\"]\n",
    "f_bdt = f[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_eval = f[\"T_eval\"].pandas.df(eval_vars, flatten=False)\n",
    "f_kine = f[\"T_KINEvars\"].pandas.df(kine_vars, flatten=False)\n",
    "f_pfeval = f[\"T_PFeval\"].pandas.df(pf_vars, flatten=False)\n",
    "nu_overlay_run3_pot = np.sum(f[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)[\"pot_tor875good\"].to_numpy())\n",
    "nu_overlay_run3_df = pd.concat([f_bdt, f_eval, f_kine, f_pfeval], axis=1, sort=False)\n",
    "nu_overlay_run3_df[\"file\"] = \"nu_overlay_run3\"\n",
    "del f\n",
    "del f_bdt\n",
    "del f_eval\n",
    "del f_kine\n",
    "del f_pfeval\n",
    "\n",
    "print(nu_overlay_run1_df.shape)\n",
    "print(nu_overlay_run2_df.shape)\n",
    "print(nu_overlay_run3_df.shape)\n",
    "\n",
    "nu_overlay_df = pd.concat([\n",
    "    nu_overlay_run1_df, \n",
    "    nu_overlay_run2_df, \n",
    "    nu_overlay_run3_df], sort=False)\n",
    "\n",
    "all_df = nu_overlay_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muon_mass = 105.66\n",
    "\n",
    "all_df[\"truth_muonMomentum_3\"] = all_df[\"truth_muonMomentum[3]\"].to_numpy()\n",
    "all_df[\"true_muon_energy\"] = all_df[\"truth_muonMomentum_3\"].to_numpy()*1000.\n",
    "all_df[\"true_muon_KE\"] = all_df[\"truth_muonMomentum_3\"].to_numpy()*1000. - muon_mass\n",
    "\n",
    "# muon_energy = sqrt(muon_momentum^2 + muon_mass^2)\n",
    "# muon_KE = muon_energy - muon_mass = sqrt(muon_momentum^2 + muon_mass^2) - muon_mass\n",
    "# sqrt(muon_momentum^2 + muon_mass^2) = muon_KE + muon_mass\n",
    "# muon_momentum = sqrt((muon_KE + muon_mass)**2 - muon_mass**2)\n",
    "# muon_momentum = sqrt(muon_KE**2 + 2*muon_KE*muon_mass)\n",
    "\n",
    "all_df[\"true_muon_momentum\"] = np.sqrt(all_df[\"true_muon_KE\"]**2 + 2*all_df[\"true_muon_KE\"] * muon_mass)\n",
    "\n",
    "all_df[\"true_muon_costheta\"] = all_df[\"truth_muonMomentum_3\"] / all_df[\"true_muon_momentum\"]\n",
    "\n",
    "# Q^2 = - (p_nu - p_mu)^2\n",
    "#     = -p_nu^2 + 2 p_nu * p_mu - p_mu^2\n",
    "#     = -m_nu^2 + 2 E_nu * E_mu - 2 * P_nu * P_mu * cos(theta) - m_mu^2\n",
    "#     = 2 E_nu * E_mu - 2 * E_nu * P_mu * cos(theta) - m_mu^2\n",
    "#     = 2 * E_nu * (E_mu - P_mu * cos(theta)) - m_mu^2\n",
    "\n",
    "all_df[\"true_Q2\"] = 2 * all_df[\"truth_nuEnergy\"] * (all_df[\"true_muon_energy\"] - all_df[\"true_muon_momentum\"] * all_df[\"true_muon_costheta\"]) - all_df[\"true_muon_KE\"]**2\n",
    "\n",
    "all_df[\"true_Q2\"] = all_df[\"true_Q2\"] / 1000.**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costheta_vals = []\n",
    "muonmomentum_vals = []\n",
    "reco_muonmomentum_x = all_df[\"reco_muonMomentum[0]\"].to_numpy()\n",
    "reco_muonmomentum_y = all_df[\"reco_muonMomentum[1]\"].to_numpy()\n",
    "reco_muonmomentum_z = all_df[\"reco_muonMomentum[2]\"].to_numpy()\n",
    "reco_muonmomentum_t = all_df[\"reco_muonMomentum[3]\"].to_numpy()\n",
    "for i in range(len(reco_muonmomentum_x)):\n",
    "    if reco_muonmomentum_t[i] < 105.66 / 1000.: # surprising that this happens for positive values, but I did find some events\n",
    "        costheta_vals.append(-1)\n",
    "        muonmomentum_vals.append(-1)\n",
    "    else:\n",
    "        costheta_vals.append(reco_muonmomentum_z[i] / np.sqrt(reco_muonmomentum_x[i]**2 + reco_muonmomentum_y[i]**2 + reco_muonmomentum_z[i]**2))\n",
    "        muon_KE = reco_muonmomentum_t[i] * 1000. - 105.66\n",
    "        muonmomentum_vals.append(np.sqrt(muon_KE**2 + 2 * muon_KE * 105.66))\n",
    "\n",
    "all_df[\"reco_costheta\"] = costheta_vals\n",
    "all_df[\"reco_muon_momentum\"] = muonmomentum_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pots = [\n",
    "    1.42319e+20,\n",
    "    2.5413e+20,\n",
    "    2.40466e+20\n",
    "]\n",
    "\n",
    "weight_cv_vals = all_df[\"weight_cv\"].to_numpy()\n",
    "weight_spline_vals = all_df[\"weight_spline\"].to_numpy()\n",
    "files = all_df[\"file\"].to_numpy()\n",
    "net_weight_vals = []\n",
    "for i in range(len(weight_cv_vals)):\n",
    "    w_cv = weight_cv_vals[i]\n",
    "    if not (0 < w_cv < 30):\n",
    "        w_cv = 1\n",
    "    \n",
    "    if files[i] == \"nu_overlay_run1\":\n",
    "        net_weight_vals.append(w_cv * weight_spline_vals[i] * data_pots[0] / nu_overlay_run1_pot)\n",
    "    elif files[i] == \"nu_overlay_run2\":\n",
    "        net_weight_vals.append(w_cv * weight_spline_vals[i] * data_pots[1] / nu_overlay_run2_pot)\n",
    "    elif files[i] == \"nu_overlay_run3\":\n",
    "        net_weight_vals.append(w_cv * weight_spline_vals[i] * data_pots[2] / nu_overlay_run3_pot)\n",
    "    \n",
    "all_df[\"net_weight\"] = net_weight_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_df = all_df.query(\"numu_cc_flag >= 0 and numu_score > 0.9 and nue_score < 7 and reco_muon_momentum>0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction Type Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using https://internal.dunescience.org/doxygen/MCNeutrino_8h_source.html\n",
    "# something weird with these variables, there are a lot of 1000 events in the file\n",
    "\"\"\"\n",
    "true_qe_query = \"1001 <= truth_nuIntType <= 1002 or truth_nuIntType == 1095\"\n",
    "true_res_query = \"1003 <= truth_nuIntType <= 1090\"\n",
    "true_dis_query = \"1091 <= truth_nuIntType <= 1092\"\n",
    "true_coh_query = \"1096 <= truth_nuIntType <= 1097\"\n",
    "true_mec_query = \"truth_nuIntType == 1100\"\n",
    "true_other_query = f\"not ({true_qe_query} or {true_res_query} or {true_dis_query} or {true_coh_query} or {true_mec_query})\"\n",
    "\"\"\"\n",
    "\n",
    "# https://internal.dunescience.org/doxygen/classgenie_1_1ScatteringType.html\n",
    "\n",
    "\"\"\"\n",
    "            case(kScUnknown) :                 return \"Uknown to GENIE\"; break;\n",
    "   67       case(kScQuasiElastic) :            return \"QES\";       break;\n",
    "   68       case(kScSingleKaon) :              return \"1Kaon\";     break;\n",
    "   69       case(kScDeepInelastic) :           return \"DIS\";       break;\n",
    "   70       case(kScResonant) :                return \"RES\";       break;\n",
    "   71       case(kScCoherentProduction) :      return \"COH\";       break;\n",
    "   72       case(kScDiffractive) :             return \"DFR\";       break;\n",
    "   73       case(kScNuElectronElastic) :       return \"NuEEL\";     break;\n",
    "   74       case(kScInverseMuDecay) :          return \"IMD\";       break;\n",
    "   75       case(kScAMNuGamma) :               return \"AMNuGamma\"; break;\n",
    "   76       case(kScMEC) :                     return \"MEC\";       break;\n",
    "   77       case(kScCoherentElastic) :         return \"CEvNS\";     break;\n",
    "   78       case(kScInverseBetaDecay) :        return \"IBD\";       break;\n",
    "   79       case(kScGlashowResonance) :        return \"GLR\";       break;\n",
    "   80       case(kScIMDAnnihilation) :         return \"IMDAnh\";    break;\n",
    "   81       case(kScDarkMatterElastic) :       return \"DMEL\";      break;\n",
    "   82       case(kScDarkMatterDeepInelastic) : return \"DMDIS\";     break;\n",
    "   83       case(kScDarkMatterElectron) :      return \"DME\";       break;\n",
    "   84       default :                          return \"Unknown\";   break;\n",
    "\"\"\"\n",
    "\n",
    "true_qe_query = \"truth_nuScatType == 1\"\n",
    "true_dis_query = \"truth_nuScatType == 3\"\n",
    "true_res_query = \"truth_nuScatType == 4\"\n",
    "true_coh_query = \"truth_nuScatType == 5\"\n",
    "true_mec_query = \"truth_nuScatType == 10\"\n",
    "true_other_query = f\"not ({true_qe_query} or {true_res_query} or {true_dis_query} or {true_coh_query} or {true_mec_query})\"\n",
    "\n",
    "sel_dfs = {}\n",
    "\n",
    "sel_dfs[\"QE\"] = sel_df.query(true_qe_query)\n",
    "sel_dfs[\"RES\"] = sel_df.query(true_res_query)\n",
    "sel_dfs[\"DIS\"] = sel_df.query(true_dis_query)\n",
    "sel_dfs[\"COH\"] = sel_df.query(true_coh_query)\n",
    "sel_dfs[\"MEC\"] = sel_df.query(true_mec_query)\n",
    "sel_dfs[\"OTHER\"] = sel_df.query(true_other_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "\n",
    "for int_type in sel_dfs.keys():\n",
    "\n",
    "    selected_df = sel_dfs[int_type]\n",
    "    counts[int_type] = []\n",
    "\n",
    "    for containment in [\"FC\", \"PC\"]:\n",
    "        \n",
    "        if containment == \"FC\":\n",
    "            containment_df = selected_df.query(\"match_isFC==1\")\n",
    "        else:\n",
    "            containment_df = selected_df.query(\"match_isFC==0\")\n",
    "            \n",
    "        for Enu_bin in range(4):\n",
    "            \n",
    "            if Enu_bin == 0:\n",
    "                Enu_df = containment_df.query(\"200 < kine_reco_Enu <= 705\")\n",
    "            elif Enu_bin == 1:\n",
    "                Enu_df = containment_df.query(\"705 < kine_reco_Enu < 1050\")\n",
    "            elif Enu_bin == 2:\n",
    "                Enu_df = containment_df.query(\"1050 < kine_reco_Enu < 1570\")\n",
    "            elif Enu_bin == 3:\n",
    "                Enu_df = containment_df.query(\"1570 < kine_reco_Enu < 4000\")\n",
    "            \n",
    "            for theta_bin in range(9):\n",
    "                \n",
    "                if theta_bin == 0:\n",
    "                    theta_df = Enu_df.query(\"-1 < reco_costheta <= -0.5\")\n",
    "                elif theta_bin == 1:\n",
    "                    theta_df = Enu_df.query(\"-0.5 < reco_costheta <= 0.\")\n",
    "                elif theta_bin == 2:\n",
    "                    theta_df = Enu_df.query(\"0. < reco_costheta <= 0.27\")\n",
    "                elif theta_bin == 3:\n",
    "                    theta_df = Enu_df.query(\"0.27 < reco_costheta <= 0.45\")\n",
    "                elif theta_bin == 4:\n",
    "                    theta_df = Enu_df.query(\"0.45 < reco_costheta <= 0.62\")\n",
    "                elif theta_bin == 5:\n",
    "                    theta_df = Enu_df.query(\"0.62 < reco_costheta <= 0.76\")\n",
    "                elif theta_bin == 6:\n",
    "                    theta_df = Enu_df.query(\"0.76 < reco_costheta <= 0.86\")\n",
    "                elif theta_bin == 7:\n",
    "                    theta_df = Enu_df.query(\"0.86 < reco_costheta <= 0.94\")\n",
    "                else:\n",
    "                    theta_df = Enu_df.query(\"0.94 < reco_costheta <= 1.\")\n",
    "                \n",
    "                counts[int_type] += list(np.histogram(theta_df[\"reco_muon_momentum\"].to_numpy(), \n",
    "                                            weights=theta_df[\"net_weight\"].to_numpy(),\n",
    "                                            bins = [i*100 for i in range(16)] + [1e9] # fifteen bins from 0 to 1500 plus an overflow\n",
    "                                            )[0])\n",
    "\n",
    "for k, v in counts.items():\n",
    "    counts[k] = np.array(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 1152, 1153)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "interaction_type_labels = [\"QE\", \"RES\", \"DIS\", \"COH\", \"MEC\", \"OTHER\"]\n",
    "\n",
    "interaction_type_stack_list = [\n",
    "    counts[\"QE\"],\n",
    "    counts[\"RES\"],\n",
    "    counts[\"DIS\"],\n",
    "    counts[\"COH\"],\n",
    "    counts[\"MEC\"],\n",
    "    counts[\"OTHER\"]\n",
    "]\n",
    "\n",
    "stack_centers = [\n",
    "    bin_centers,\n",
    "    bin_centers,\n",
    "    bin_centers,\n",
    "    bin_centers,\n",
    "    bin_centers,\n",
    "    bin_centers\n",
    "]\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.hist(stack_centers, weights=interaction_type_stack_list, label=interaction_type_labels, stacked=True, bins=bins)\n",
    "plt.legend()\n",
    "plt.xlabel(\"reco bin number\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.xlim(0, 1152)\n",
    "plt.savefig(\"plots/ccqe_vs_nonccqe.png\")\n",
    "plt.savefig(\"plots/ccqe_vs_nonccqe.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = counts[\"QE\"] + counts[\"RES\"] + counts[\"DIS\"] + counts[\"COH\"] + counts[\"MEC\"] + counts[\"OTHER\"]\n",
    "\n",
    "interaction_type_frac_counts = [\n",
    "    np.nan_to_num(counts[\"QE\"] / total_counts, nan=0),\n",
    "    np.nan_to_num(counts[\"RES\"] / total_counts, nan=0),\n",
    "    np.nan_to_num(counts[\"DIS\"] / total_counts, nan=0),\n",
    "    np.nan_to_num(counts[\"COH\"] / total_counts, nan=0),\n",
    "    np.nan_to_num(counts[\"MEC\"] / total_counts, nan=0),\n",
    "    np.nan_to_num(counts[\"OTHER\"] / total_counts, nan=0)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "n, bins, patches = plt.hist(stack_centers, weights=interaction_type_frac_counts, label=interaction_type_labels, stacked=True, bins=bins)\n",
    "plt.legend()\n",
    "plt.xlabel(\"reco bin number\")\n",
    "plt.ylabel(\"fraction\")\n",
    "plt.xlim(0, 1152)\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(\"plots/ccqe_vs_nonccqe_frac.png\")\n",
    "plt.savefig(\"plots/ccqe_vs_nonccqe_frac.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_total_count_indices = np.where(total_counts < 10)[0]\n",
    "\n",
    "interaction_type_low_removed_frac_counts = []\n",
    "interaction_type_low_removed_stack_centers = []\n",
    "for interaction_type_frac_count, interaction_type_stack_center in zip(interaction_type_frac_counts, stack_centers):\n",
    "    interaction_type_low_removed_frac_counts.append(np.delete(interaction_type_frac_count, low_total_count_indices))\n",
    "\n",
    "num_low_removed_bins = len(interaction_type_low_removed_frac_counts[0])\n",
    "\n",
    "interaction_type_low_removed_bins = np.linspace(0, num_low_removed_bins, num_low_removed_bins + 1)\n",
    "interaction_type_low_removed_bin_centers = (interaction_type_low_removed_bins[:-1] + interaction_type_low_removed_bins[1:]) / 2\n",
    "interaction_type_low_removed_stack_centers = [interaction_type_low_removed_bin_centers] * len(interaction_type_labels)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "n, bins, patches = plt.hist(interaction_type_low_removed_stack_centers, \n",
    "                            weights=interaction_type_low_removed_frac_counts, \n",
    "                            label=interaction_type_labels, \n",
    "                            stacked=True, \n",
    "                            bins=interaction_type_low_removed_bins)\n",
    "plt.legend()\n",
    "plt.xlabel(\"reco bin number, removing bins with low predicted counts\")\n",
    "plt.ylabel(\"fraction\")\n",
    "plt.xlim(0, interaction_type_low_removed_bins[-1])\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(\"plots/low_removed_ccqe_vs_nonccqe_frac.png\")\n",
    "plt.savefig(\"plots/low_removed_ccqe_vs_nonccqe_frac.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_fractions = interaction_type_low_removed_frac_counts[0]\n",
    "\n",
    "interaction_type_sort_indices = np.argsort(qe_fractions)\n",
    "\n",
    "interaction_type_sorted_frac_counts = []\n",
    "for interaction_type_frac_count in interaction_type_low_removed_frac_counts:\n",
    "    interaction_type_sorted_frac_counts.append(interaction_type_frac_count[interaction_type_sort_indices])\n",
    "\n",
    "num_bins = len(interaction_type_sorted_frac_counts[0])\n",
    "interaction_type_sorted_bins = np.linspace(0, num_bins, num_bins + 1)\n",
    "interaction_type_sorted_bin_centers = (interaction_type_sorted_bins[:-1] + interaction_type_sorted_bins[1:]) / 2\n",
    "interaction_type_sorted_stack_centers = [interaction_type_sorted_bin_centers] * len(interaction_type_labels)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "n, bins, patches = plt.hist(interaction_type_sorted_stack_centers, \n",
    "                          weights=interaction_type_sorted_frac_counts, \n",
    "                          label=interaction_type_labels, \n",
    "                          stacked=True, \n",
    "                          bins=interaction_type_sorted_bins)\n",
    "plt.legend()\n",
    "plt.xlabel(\"reco bin number, sorted by QE fraction, no low-pred bins\")\n",
    "plt.ylabel(\"fraction\")\n",
    "plt.xlim(0, interaction_type_sorted_bins[-1])\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(\"plots/sorted_ccqe_vs_nonccqe_frac.png\")\n",
    "plt.savefig(\"plots/sorted_ccqe_vs_nonccqe_frac.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# True Q^2 Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth_nuEnergy > true_muon_energy cuts out a tiny number of weird events, probably with two neutrinos in the same simulation?\n",
    "true_numuCC_sel_df = sel_df.query(\"truth_nuEnergy > true_muon_energy and true_muon_energy > 0\") \n",
    "\n",
    "cutoffs = [0] + list(np.quantile(true_numuCC_sel_df[\"true_Q2\"].to_numpy(), [0.25, 0.5, 0.75])) + [1e9]\n",
    "print(cutoffs)\n",
    "\n",
    "print(np.min(true_numuCC_sel_df[\"true_Q2\"].to_numpy()))\n",
    "print(np.max(true_numuCC_sel_df[\"true_Q2\"].to_numpy()))\n",
    "plt.hist(true_numuCC_sel_df[\"true_Q2\"].to_numpy(), bins=100)\n",
    "plt.xlabel(\"True Q^2\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"True Q^2 for selected true numu CC events\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_sel_dfs = {}\n",
    "\n",
    "q2_sel_dfs[\"all\"] = true_numuCC_sel_df\n",
    "q2_sel_dfs[\"1\"] = true_numuCC_sel_df.query(f\"{cutoffs[0]} < true_Q2 <= {cutoffs[1]}\")\n",
    "q2_sel_dfs[\"2\"] = true_numuCC_sel_df.query(f\"{cutoffs[1]} < true_Q2 <= {cutoffs[2]}\")\n",
    "q2_sel_dfs[\"3\"] = true_numuCC_sel_df.query(f\"{cutoffs[2]} < true_Q2 <= {cutoffs[3]}\")\n",
    "q2_sel_dfs[\"4\"] = true_numuCC_sel_df.query(f\"{cutoffs[3]} < true_Q2\")\n",
    "q2_sel_dfs[\"QE\"] = true_numuCC_sel_df.query(true_qe_query)\n",
    "q2_sel_dfs[\"non-QE\"] = true_numuCC_sel_df.query(f\"not ({true_qe_query})\")\n",
    "\n",
    "median_q2_by_bin = []\n",
    "\n",
    "q2_counts = {}\n",
    "\n",
    "for quantile_str in q2_sel_dfs.keys():\n",
    "\n",
    "    selected_df = q2_sel_dfs[quantile_str]\n",
    "    q2_counts[quantile_str] = []\n",
    "\n",
    "    for containment in [\"FC\", \"PC\"]:\n",
    "        \n",
    "        if containment == \"FC\":\n",
    "            containment_df = selected_df.query(\"match_isFC==1\")\n",
    "        else:\n",
    "            containment_df = selected_df.query(\"match_isFC==0\")\n",
    "            \n",
    "        for Enu_bin in range(4):\n",
    "            \n",
    "            if Enu_bin == 0:\n",
    "                Enu_df = containment_df.query(\"200 < kine_reco_Enu <= 705\")\n",
    "            elif Enu_bin == 1:\n",
    "                Enu_df = containment_df.query(\"705 < kine_reco_Enu < 1050\")\n",
    "            elif Enu_bin == 2:\n",
    "                Enu_df = containment_df.query(\"1050 < kine_reco_Enu < 1570\")\n",
    "            elif Enu_bin == 3:\n",
    "                Enu_df = containment_df.query(\"1570 < kine_reco_Enu < 4000\")\n",
    "            \n",
    "            for theta_bin in range(9):\n",
    "                \n",
    "                if theta_bin == 0:\n",
    "                    theta_df = Enu_df.query(\"-1 < reco_costheta <= -0.5\")\n",
    "                elif theta_bin == 1:\n",
    "                    theta_df = Enu_df.query(\"-0.5 < reco_costheta <= 0.\")\n",
    "                elif theta_bin == 2:\n",
    "                    theta_df = Enu_df.query(\"0. < reco_costheta <= 0.27\")\n",
    "                elif theta_bin == 3:\n",
    "                    theta_df = Enu_df.query(\"0.27 < reco_costheta <= 0.45\")\n",
    "                elif theta_bin == 4:\n",
    "                    theta_df = Enu_df.query(\"0.45 < reco_costheta <= 0.62\")\n",
    "                elif theta_bin == 5:\n",
    "                    theta_df = Enu_df.query(\"0.62 < reco_costheta <= 0.76\")\n",
    "                elif theta_bin == 6:\n",
    "                    theta_df = Enu_df.query(\"0.76 < reco_costheta <= 0.86\")\n",
    "                elif theta_bin == 7:\n",
    "                    theta_df = Enu_df.query(\"0.86 < reco_costheta <= 0.94\")\n",
    "                else:\n",
    "                    theta_df = Enu_df.query(\"0.94 < reco_costheta <= 1.\")\n",
    "                \n",
    "                q2_counts[quantile_str] += list(np.histogram(theta_df[\"reco_muon_momentum\"].to_numpy(), \n",
    "                                            weights=theta_df[\"net_weight\"].to_numpy(),\n",
    "                                            bins = [i*100 for i in range(16)] + [1e9] # fifteen bins from 0 to 1500 plus an overflow\n",
    "                                            )[0])\n",
    "                \n",
    "                if quantile_str == \"all\":\n",
    "                    for i in range(16):\n",
    "                        curr_bin_df = theta_df.query(f\"reco_muon_momentum >= {i*100} and reco_muon_momentum < {(i+1)*100}\")\n",
    "                        median_q2_by_bin.append(np.median(curr_bin_df[\"true_Q2\"].to_numpy()))\n",
    "\n",
    "for k, v in q2_counts.items():\n",
    "    q2_counts[k] = np.array(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 1152, 1153)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "q2_labels = [f\"$Q^2$ < {cutoffs[1]:.2f}\", \n",
    "          f\"{cutoffs[1]:.2f} < $Q^2$ < {cutoffs[2]:.2f}\", \n",
    "          f\"{cutoffs[2]:.2f} < $Q^2$ < {cutoffs[3]:.2f}\", \n",
    "          f\"{cutoffs[3]:.2f} < $Q^2$\"\n",
    "          ]\n",
    "\n",
    "q2_stack_list = [\n",
    "    q2_counts[\"1\"],\n",
    "    q2_counts[\"2\"],\n",
    "    q2_counts[\"3\"],\n",
    "    q2_counts[\"4\"],\n",
    "]\n",
    "\n",
    "stack_centers = [\n",
    "    bin_centers,\n",
    "    bin_centers,\n",
    "    bin_centers,\n",
    "    bin_centers,\n",
    "]\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.hist(stack_centers, weights=q2_stack_list, label=q2_labels, stacked=True, bins=bins)\n",
    "plt.legend()\n",
    "plt.xlabel(\"reco bin number\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.xlim(0, 1152)\n",
    "plt.savefig(\"plots/quantiles.png\")\n",
    "plt.savefig(\"plots/quantiles.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = q2_counts[\"1\"] + q2_counts[\"2\"] + q2_counts[\"3\"] + q2_counts[\"4\"]\n",
    "\n",
    "q2_QE_frac_count = q2_counts[\"QE\"] / total_counts\n",
    "\n",
    "q2_frac_counts = [\n",
    "    np.nan_to_num(q2_counts[\"1\"] / total_counts, nan=0),\n",
    "    np.nan_to_num(q2_counts[\"2\"] / total_counts, nan=0),\n",
    "    np.nan_to_num(q2_counts[\"3\"] / total_counts, nan=0),\n",
    "    np.nan_to_num(q2_counts[\"4\"] / total_counts, nan=0),\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "n, bins, patches = plt.hist(stack_centers, weights=q2_frac_counts, label=q2_labels, stacked=True, bins=bins)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"reco bin number\")\n",
    "plt.ylabel(\"fraction\")\n",
    "plt.xlim(0, 1152)\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(\"plots/quantiles_frac.png\")\n",
    "plt.savefig(\"plots/quantiles_frac.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_low_total_count_indices = np.where(total_counts < 10)[0]\n",
    "\n",
    "q2_low_removed_frac_counts = []\n",
    "q2_low_removed_stack_centers = []\n",
    "for q2_frac_count, q2_stack_center in zip(q2_frac_counts, stack_centers):\n",
    "    q2_low_removed_frac_counts.append(np.delete(q2_frac_count, q2_low_total_count_indices))\n",
    "q2_low_removed_median_q2_by_bin = np.delete(median_q2_by_bin, q2_low_total_count_indices)\n",
    "\n",
    "q2_low_removed_QE_frac_count = np.delete(q2_QE_frac_count, q2_low_total_count_indices)\n",
    "\n",
    "num_low_removed_bins = len(q2_low_removed_frac_counts[0])\n",
    "\n",
    "q2_low_removed_bins = np.linspace(0, num_low_removed_bins, num_low_removed_bins + 1)\n",
    "q2_low_removed_bin_centers = (q2_low_removed_bins[:-1] + q2_low_removed_bins[1:]) / 2\n",
    "q2_low_removed_stack_centers = [q2_low_removed_bin_centers] * len(q2_labels)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "n, bins, patches = plt.hist(q2_low_removed_stack_centers, \n",
    "                            weights=q2_low_removed_frac_counts, \n",
    "                            label=q2_labels, \n",
    "                            stacked=True, \n",
    "                            bins=q2_low_removed_bins)\n",
    "plt.legend()\n",
    "plt.xlabel(\"reco bin number, removing bins with low predicted counts\")\n",
    "plt.ylabel(\"fraction\")\n",
    "plt.xlim(0, q2_low_removed_bins[-1])\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(\"plots/low_removed_quantiles_frac.png\")\n",
    "plt.savefig(\"plots/low_removed_quantiles_frac.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_sort_indices = np.argsort(q2_low_removed_median_q2_by_bin)\n",
    "\n",
    "q2_sorted_frac_counts = []\n",
    "for q2_frac_count in q2_low_removed_frac_counts:\n",
    "    q2_sorted_frac_counts.append(q2_frac_count[q2_sort_indices])\n",
    "\n",
    "num_bins = len(q2_sorted_frac_counts[0])\n",
    "q2_sorted_bins = np.linspace(0, num_bins, num_bins + 1)\n",
    "q2_sorted_bin_centers = (q2_sorted_bins[:-1] + q2_sorted_bins[1:]) / 2\n",
    "q2_sorted_stack_centers = [q2_sorted_bin_centers] * len(q2_labels)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "n, bins, patches = plt.hist(q2_sorted_stack_centers, \n",
    "                          weights=q2_sorted_frac_counts, \n",
    "                          label=q2_labels, \n",
    "                          stacked=True, \n",
    "                          bins=q2_sorted_bins)\n",
    "plt.legend()\n",
    "plt.xlabel(f\"reco bin number, sorted by median $Q^2$\")\n",
    "plt.ylabel(\"fraction\")\n",
    "plt.xlim(0, q2_sorted_bins[-1])\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(\"plots/sorted_quantiles_frac.png\")\n",
    "plt.savefig(\"plots/sorted_quantiles_frac.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Q^2 vs QE Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(q2_low_removed_median_q2_by_bin, q2_low_removed_QE_frac_count, c=\"k\", s=1)\n",
    "plt.xlabel(\"Median $Q^2$\")\n",
    "plt.ylabel(\"QE Fraction\")\n",
    "plt.title(\"4D Reco Bins, low-stat removed\")\n",
    "plt.savefig(\"plots/q2_vs_qe_frac_low_stat_removed.png\")\n",
    "plt.savefig(\"plots/q2_vs_qe_frac_low_stat_removed.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four Panel True Q^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four panel plot of ccqe vs nonccqe by true Q^2\n",
    "\n",
    "# make 4x1 subplots\n",
    "fig, axs = plt.subplots(4, 1, figsize=(15, 15))\n",
    "\n",
    "for Q_bin in range(4):\n",
    "\n",
    "    qbin_sel_df = true_numuCC_sel_df.query(f\"{cutoffs[Q_bin]} < true_Q2 <= {cutoffs[Q_bin+1]}\")\n",
    "\n",
    "    sel_dfs = {}\n",
    "\n",
    "    sel_dfs[\"QE\"] = qbin_sel_df.query(true_qe_query)\n",
    "    sel_dfs[\"RES\"] = qbin_sel_df.query(true_res_query)\n",
    "    sel_dfs[\"DIS\"] = qbin_sel_df.query(true_dis_query)\n",
    "    sel_dfs[\"COH\"] = qbin_sel_df.query(true_coh_query)\n",
    "    sel_dfs[\"MEC\"] = qbin_sel_df.query(true_mec_query)\n",
    "    sel_dfs[\"OTHER\"] = qbin_sel_df.query(true_other_query)\n",
    "\n",
    "    counts = {}\n",
    "\n",
    "    for int_type in sel_dfs.keys():\n",
    "\n",
    "        selected_df = sel_dfs[int_type]\n",
    "        counts[int_type] = []\n",
    "\n",
    "        for containment in [\"FC\", \"PC\"]:\n",
    "            \n",
    "            if containment == \"FC\":\n",
    "                containment_df = selected_df.query(\"match_isFC==1\")\n",
    "            else:\n",
    "                containment_df = selected_df.query(\"match_isFC==0\")\n",
    "                \n",
    "            for Enu_bin in range(4):\n",
    "                \n",
    "                if Enu_bin == 0:\n",
    "                    Enu_df = containment_df.query(\"200 < kine_reco_Enu <= 705\")\n",
    "                elif Enu_bin == 1:\n",
    "                    Enu_df = containment_df.query(\"705 < kine_reco_Enu < 1050\")\n",
    "                elif Enu_bin == 2:\n",
    "                    Enu_df = containment_df.query(\"1050 < kine_reco_Enu < 1570\")\n",
    "                elif Enu_bin == 3:\n",
    "                    Enu_df = containment_df.query(\"1570 < kine_reco_Enu < 4000\")\n",
    "                \n",
    "                for theta_bin in range(9):\n",
    "                    \n",
    "                    if theta_bin == 0:\n",
    "                        theta_df = Enu_df.query(\"-1 < reco_costheta <= -0.5\")\n",
    "                    elif theta_bin == 1:\n",
    "                        theta_df = Enu_df.query(\"-0.5 < reco_costheta <= 0.\")\n",
    "                    elif theta_bin == 2:\n",
    "                        theta_df = Enu_df.query(\"0. < reco_costheta <= 0.27\")\n",
    "                    elif theta_bin == 3:\n",
    "                        theta_df = Enu_df.query(\"0.27 < reco_costheta <= 0.45\")\n",
    "                    elif theta_bin == 4:\n",
    "                        theta_df = Enu_df.query(\"0.45 < reco_costheta <= 0.62\")\n",
    "                    elif theta_bin == 5:\n",
    "                        theta_df = Enu_df.query(\"0.62 < reco_costheta <= 0.76\")\n",
    "                    elif theta_bin == 6:\n",
    "                        theta_df = Enu_df.query(\"0.76 < reco_costheta <= 0.86\")\n",
    "                    elif theta_bin == 7:\n",
    "                        theta_df = Enu_df.query(\"0.86 < reco_costheta <= 0.94\")\n",
    "                    else:\n",
    "                        theta_df = Enu_df.query(\"0.94 < reco_costheta <= 1.\")\n",
    "                    \n",
    "                    counts[int_type] += list(np.histogram(theta_df[\"reco_muon_momentum\"].to_numpy(), \n",
    "                                                weights=theta_df[\"net_weight\"].to_numpy(),\n",
    "                                                bins = [i*100 for i in range(16)] + [1e9] # fifteen bins from 0 to 1500 plus an overflow\n",
    "                                                )[0])\n",
    "\n",
    "    for k, v in counts.items():\n",
    "        counts[k] = np.array(v)\n",
    "\n",
    "\n",
    "    bins = np.linspace(0, 1152, 1153)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "    labels = [\"QE\", \"RES\", \"DIS\", \"COH\", \"MEC\", \"OTHER\"]\n",
    "\n",
    "    stack_list = [\n",
    "        counts[\"QE\"],\n",
    "        counts[\"RES\"],\n",
    "        counts[\"DIS\"],\n",
    "        counts[\"COH\"],\n",
    "        counts[\"MEC\"],\n",
    "        counts[\"OTHER\"]\n",
    "    ]\n",
    "\n",
    "    stack_centers = [\n",
    "        bin_centers,\n",
    "        bin_centers,\n",
    "        bin_centers,\n",
    "        bin_centers,\n",
    "        bin_centers,\n",
    "        bin_centers\n",
    "    ]\n",
    "\n",
    "    axs[Q_bin].hist(stack_centers, weights=stack_list, label=labels, stacked=True, bins=bins)\n",
    "    if Q_bin == 0:\n",
    "        axs[Q_bin].legend()\n",
    "    if Q_bin == 3:\n",
    "        axs[Q_bin].set_xlabel(\"reco bin number\")\n",
    "    axs[Q_bin].set_ylabel(\"counts\")\n",
    "    axs[Q_bin].set_xlim(0, 1152)\n",
    "    if Q_bin == 0:\n",
    "        axs[Q_bin].text(0.1, 0.8, f\"$Q^2$ < {cutoffs[Q_bin+1]:.2f}\", transform=axs[Q_bin].transAxes, fontsize=16)\n",
    "    elif Q_bin == 3:\n",
    "        axs[Q_bin].text(0.1, 0.8, f\"{cutoffs[Q_bin]:.2f} < $Q^2$\", transform=axs[Q_bin].transAxes, fontsize=16)\n",
    "    else:\n",
    "        axs[Q_bin].text(0.1, 0.8, f\"{cutoffs[Q_bin]:.2f} < $Q^2$ < {cutoffs[Q_bin+1]:.2f}\", transform=axs[Q_bin].transAxes, fontsize=16)\n",
    "\n",
    "plt.savefig(\"plots/q2_slices.png\")\n",
    "plt.savefig(\"plots/q2_slices.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four panel plot of ccqe vs nonccqe by true Q^2\n",
    "\n",
    "# make 4x1 subplots\n",
    "fig, axs = plt.subplots(4, 1, figsize=(15, 15))\n",
    "\n",
    "for Q_bin in range(4):\n",
    "\n",
    "    qbin_sel_df = true_numuCC_sel_df.query(f\"{cutoffs[Q_bin]} < true_Q2 <= {cutoffs[Q_bin+1]}\")\n",
    "\n",
    "    sel_dfs = {}\n",
    "\n",
    "    sel_dfs[\"QE\"] = qbin_sel_df.query(true_qe_query)\n",
    "    sel_dfs[\"RES\"] = qbin_sel_df.query(true_res_query)\n",
    "    sel_dfs[\"DIS\"] = qbin_sel_df.query(true_dis_query)\n",
    "    sel_dfs[\"COH\"] = qbin_sel_df.query(true_coh_query)\n",
    "    sel_dfs[\"MEC\"] = qbin_sel_df.query(true_mec_query)\n",
    "    sel_dfs[\"OTHER\"] = qbin_sel_df.query(true_other_query)\n",
    "\n",
    "    counts = {}\n",
    "\n",
    "    for int_type in sel_dfs.keys():\n",
    "\n",
    "        selected_df = sel_dfs[int_type]\n",
    "        counts[int_type] = []\n",
    "\n",
    "        for containment in [\"FC\", \"PC\"]:\n",
    "            \n",
    "            if containment == \"FC\":\n",
    "                containment_df = selected_df.query(\"match_isFC==1\")\n",
    "            else:\n",
    "                containment_df = selected_df.query(\"match_isFC==0\")\n",
    "                \n",
    "            for Enu_bin in range(4):\n",
    "                \n",
    "                if Enu_bin == 0:\n",
    "                    Enu_df = containment_df.query(\"200 < kine_reco_Enu <= 705\")\n",
    "                elif Enu_bin == 1:\n",
    "                    Enu_df = containment_df.query(\"705 < kine_reco_Enu < 1050\")\n",
    "                elif Enu_bin == 2:\n",
    "                    Enu_df = containment_df.query(\"1050 < kine_reco_Enu < 1570\")\n",
    "                elif Enu_bin == 3:\n",
    "                    Enu_df = containment_df.query(\"1570 < kine_reco_Enu < 4000\")\n",
    "                \n",
    "                for theta_bin in range(9):\n",
    "                    \n",
    "                    if theta_bin == 0:\n",
    "                        theta_df = Enu_df.query(\"-1 < reco_costheta <= -0.5\")\n",
    "                    elif theta_bin == 1:\n",
    "                        theta_df = Enu_df.query(\"-0.5 < reco_costheta <= 0.\")\n",
    "                    elif theta_bin == 2:\n",
    "                        theta_df = Enu_df.query(\"0. < reco_costheta <= 0.27\")\n",
    "                    elif theta_bin == 3:\n",
    "                        theta_df = Enu_df.query(\"0.27 < reco_costheta <= 0.45\")\n",
    "                    elif theta_bin == 4:\n",
    "                        theta_df = Enu_df.query(\"0.45 < reco_costheta <= 0.62\")\n",
    "                    elif theta_bin == 5:\n",
    "                        theta_df = Enu_df.query(\"0.62 < reco_costheta <= 0.76\")\n",
    "                    elif theta_bin == 6:\n",
    "                        theta_df = Enu_df.query(\"0.76 < reco_costheta <= 0.86\")\n",
    "                    elif theta_bin == 7:\n",
    "                        theta_df = Enu_df.query(\"0.86 < reco_costheta <= 0.94\")\n",
    "                    else:\n",
    "                        theta_df = Enu_df.query(\"0.94 < reco_costheta <= 1.\")\n",
    "                    \n",
    "                    counts[int_type] += list(np.histogram(theta_df[\"reco_muon_momentum\"].to_numpy(), \n",
    "                                                weights=theta_df[\"net_weight\"].to_numpy(),\n",
    "                                                bins = [i*100 for i in range(16)] + [1e9] # fifteen bins from 0 to 1500 plus an overflow\n",
    "                                                )[0])\n",
    "\n",
    "    for k, v in counts.items():\n",
    "        counts[k] = np.array(v)\n",
    "\n",
    "\n",
    "    bins = np.linspace(0, 1152, 1153)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "    labels = [\"QE\", \"RES\", \"DIS\", \"COH\", \"MEC\", \"OTHER\"]\n",
    "\n",
    "    stack_centers = [\n",
    "        bin_centers,\n",
    "        bin_centers,\n",
    "        bin_centers,\n",
    "        bin_centers,\n",
    "        bin_centers,\n",
    "        bin_centers\n",
    "    ]\n",
    "\n",
    "    total_counts = counts[\"QE\"] + counts[\"RES\"] + counts[\"DIS\"] + counts[\"COH\"] + counts[\"MEC\"] + counts[\"OTHER\"]\n",
    "\n",
    "    frac_counts = [\n",
    "        np.nan_to_num(counts[\"QE\"] / total_counts, nan=0),\n",
    "        np.nan_to_num(counts[\"RES\"] / total_counts, nan=0),\n",
    "        np.nan_to_num(counts[\"DIS\"] / total_counts, nan=0),\n",
    "        np.nan_to_num(counts[\"COH\"] / total_counts, nan=0),\n",
    "        np.nan_to_num(counts[\"MEC\"] / total_counts, nan=0),\n",
    "        np.nan_to_num(counts[\"OTHER\"] / total_counts, nan=0)\n",
    "    ]\n",
    "\n",
    "    low_total_count_indices = np.where(total_counts < 10)[0]\n",
    "\n",
    "    low_removed_frac_counts = []\n",
    "    low_removed_stack_centers = []\n",
    "    for frac_count, stack_center in zip(frac_counts, stack_centers):\n",
    "        low_removed_frac_counts.append(np.delete(frac_count, low_total_count_indices))\n",
    "    low_removed_median_q2_by_bin = np.delete(median_q2_by_bin, low_total_count_indices)\n",
    "\n",
    "    num_low_removed_bins = len(low_removed_frac_counts[0])\n",
    "\n",
    "    low_removed_bins = np.linspace(0, num_low_removed_bins, num_low_removed_bins + 1)\n",
    "    low_removed_bin_centers = (low_removed_bins[:-1] + low_removed_bins[1:]) / 2\n",
    "    low_removed_stack_centers = [low_removed_bin_centers] * len(labels)\n",
    "\n",
    "    qe_fractions = low_removed_frac_counts[0]\n",
    "    sort_indices = np.argsort(qe_fractions)\n",
    "    sorted_frac_counts = []\n",
    "    for frac_count in low_removed_frac_counts:\n",
    "        sorted_frac_counts.append(frac_count[sort_indices])\n",
    "    num_bins = len(sorted_frac_counts[0])\n",
    "    sorted_bins = np.linspace(0, num_bins, num_bins + 1)\n",
    "    sorted_bin_centers = (sorted_bins[:-1] + sorted_bins[1:]) / 2\n",
    "    sorted_stack_centers = [sorted_bin_centers] * len(labels)\n",
    "\n",
    "    axs[Q_bin].hist(sorted_stack_centers, weights=sorted_frac_counts, label=labels, stacked=True, bins=sorted_bins)\n",
    "    if Q_bin == 0:\n",
    "        axs[Q_bin].legend()\n",
    "    if Q_bin == 3:\n",
    "        axs[Q_bin].set_xlabel(\"reco bin number, sorted by QE fraction, no low-pred bins\")\n",
    "\n",
    "    axs[Q_bin].set_ylabel(\"fraction\")\n",
    "    axs[Q_bin].set_xlim(0, len(low_removed_bins))\n",
    "    axs[Q_bin].set_ylim(0, 1)\n",
    "    if Q_bin == 0:\n",
    "        axs[Q_bin].text(0.6, 0.1, f\"$Q^2$ < {cutoffs[Q_bin+1]:.2f}\", transform=axs[Q_bin].transAxes, fontsize=16)\n",
    "    elif Q_bin == 3:\n",
    "        axs[Q_bin].text(0.6, 0.1, f\"{cutoffs[Q_bin]:.2f} < $Q^2$\", transform=axs[Q_bin].transAxes, fontsize=16)\n",
    "    else:\n",
    "        axs[Q_bin].text(0.6, 0.1, f\"{cutoffs[Q_bin]:.2f} < $Q^2$ < {cutoffs[Q_bin+1]:.2f}\", transform=axs[Q_bin].transAxes, fontsize=16)\n",
    "\n",
    "plt.savefig(\"plots/q2_slices_sorted_by_qe_frac.png\")\n",
    "plt.savefig(\"plots/q2_slices_sorted_by_qe_frac.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
