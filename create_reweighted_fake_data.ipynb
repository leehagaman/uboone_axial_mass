{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uproot as uproot\n",
    "import uproot3 as uproot3\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is currently unused, just here to explore the possibility of adding more fake data tests in the future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this fake data has to use PF files to get E_avail\n",
    "# London used non-PF files for the prediction and systematics I'm using, but this is a small change that shouldn't really matter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate 3D cross sections of P_mu, cos(theta_mu), and E_avail\n",
    "# For the uboonetune as a reference, and for different generators with different M_A or z-expansion values\n",
    "# Reweighting isn't perfect, but this should basically cover the information we're using, and should serve as\n",
    "# an additional robust set of fake data tests with a more diverse set of nuclear treatments and M_A spreads\n",
    "\n",
    "uboone_xs = np.ones((100, 100, 100)) # to be calculated\n",
    "\n",
    "gibuu_MA_1_3_xs = np.ones((100, 100, 100)) # to be calculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_vars = [\n",
    "    \"nue_score\",\n",
    "    \"numu_score\",\n",
    "    \"numu_cc_flag\"\n",
    "]\n",
    "\n",
    "eval_vars = [\n",
    "    \"run\",\n",
    "    \"subrun\",\n",
    "    \"event\",\n",
    "    \"truth_nuEnergy\",\n",
    "    \"truth_nuPdg\",\n",
    "    \"truth_isCC\",\n",
    "    \"truth_vtxInside\",\n",
    "    \"match_isFC\",\n",
    "    \"match_completeness_energy\",\n",
    "    \"truth_energyInside\",\n",
    "\n",
    "    \"weight_cv\",\n",
    "    \"weight_spline\",\n",
    "]\n",
    "\n",
    "kine_vars = [\n",
    "    \"kine_reco_Enu\",\n",
    "]\n",
    "\n",
    "pf_vars = [\n",
    "    \"reco_muonMomentum\",\n",
    "    \"truth_muonMomentum\",\n",
    "\n",
    "    \"truth_Ntrack\",\n",
    "    \"truth_pdg\",\n",
    "    \"truth_mother\",\n",
    "    \"truth_vtxX\",\n",
    "    \"truth_vtxY\",\n",
    "    \"truth_vtxZ\",\n",
    "    \"truth_startXYZT\",\n",
    "    \"truth_startMomentum\",\n",
    "]\n",
    "\n",
    "\n",
    "weight_vars = [\n",
    "    # the framework never uses these, it uses the ones in T_eval instead!\n",
    "    #\"weight_cv\",\n",
    "    #\"weight_spline\",\n",
    "\n",
    "    \"All_UBGenie\",\n",
    "    \n",
    "    \"AxFFCCQEshape_UBGenie\",\n",
    "    \"DecayAngMEC_UBGenie\",\n",
    "    \"NormCCCOH_UBGenie\",\n",
    "    \"NormNCCOH_UBGenie\",\n",
    "    \"RPA_CCQE_UBGenie\",\n",
    "    \"ThetaDelta2NRad_UBGenie\",\n",
    "    \"Theta_Delta2Npi_UBGenie\",\n",
    "    \"VecFFCCQEshape_UBGenie\",\n",
    "    \"XSecShape_CCMEC_UBGenie\",\n",
    "    \"xsr_scc_Fa3_SCC\",\n",
    "    \"xsr_scc_Fv3_SCC\",\n",
    "]\n",
    "\n",
    "loc = \"/Users/leehagaman/data/processed_checkout_rootfiles/\"\n",
    "#loc = \"/Users/leehagaman/data/from_london/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = uproot3.open(loc + \"checkout_prodgenie_bnb_nu_overlay_run1_PF.root\")[\"wcpselection\"]\n",
    "f_bdt = f[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_eval = f[\"T_eval\"].pandas.df(eval_vars, flatten=False)\n",
    "f_kine = f[\"T_KINEvars\"].pandas.df(kine_vars, flatten=False)\n",
    "f_pfeval = f[\"T_PFeval\"].pandas.df(pf_vars, flatten=False)\n",
    "nu_overlay_run1_pot = np.sum(f[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)[\"pot_tor875good\"].to_numpy())\n",
    "nu_overlay_run1_df = pd.concat([f_bdt, f_eval, f_kine, f_pfeval], axis=1, sort=False)\n",
    "nu_overlay_run1_df[\"file\"] = \"nu_overlay_run1\"\n",
    "del f\n",
    "del f_bdt\n",
    "del f_eval\n",
    "del f_kine\n",
    "del f_pfeval\n",
    "\n",
    "print(nu_overlay_run1_df.shape)\n",
    "\n",
    "f = uproot3.open(loc + \"checkout_prodgenie_bnb_nu_overlay_run2_PF.root\")[\"wcpselection\"]\n",
    "f_bdt = f[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_eval = f[\"T_eval\"].pandas.df(eval_vars, flatten=False)\n",
    "f_kine = f[\"T_KINEvars\"].pandas.df(kine_vars, flatten=False)\n",
    "f_pfeval = f[\"T_PFeval\"].pandas.df(pf_vars, flatten=False)\n",
    "nu_overlay_run2_pot = np.sum(f[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)[\"pot_tor875good\"].to_numpy())\n",
    "nu_overlay_run2_df = pd.concat([f_bdt, f_eval, f_kine, f_pfeval], axis=1, sort=False)\n",
    "nu_overlay_run2_df[\"file\"] = \"nu_overlay_run2\"\n",
    "del f\n",
    "del f_bdt\n",
    "del f_eval\n",
    "del f_kine\n",
    "del f_pfeval\n",
    "\n",
    "print(nu_overlay_run2_df.shape)\n",
    "\n",
    "f = uproot3.open(loc + \"checkout_prodgenie_bnb_nu_overlay_run3_PF.root\")[\"wcpselection\"]\n",
    "f_bdt = f[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_eval = f[\"T_eval\"].pandas.df(eval_vars, flatten=False)\n",
    "f_kine = f[\"T_KINEvars\"].pandas.df(kine_vars, flatten=False)\n",
    "f_pfeval = f[\"T_PFeval\"].pandas.df(pf_vars, flatten=False)\n",
    "nu_overlay_run3_pot = np.sum(f[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)[\"pot_tor875good\"].to_numpy())\n",
    "nu_overlay_run3_df = pd.concat([f_bdt, f_eval, f_kine, f_pfeval], axis=1, sort=False)\n",
    "nu_overlay_run3_df[\"file\"] = \"nu_overlay_run3\"\n",
    "del f\n",
    "del f_bdt\n",
    "del f_eval\n",
    "del f_kine\n",
    "del f_pfeval\n",
    "\n",
    "print(nu_overlay_run3_df.shape)\n",
    "\n",
    "all_df = pd.concat([\n",
    "    nu_overlay_run1_df, \n",
    "    nu_overlay_run2_df, \n",
    "    nu_overlay_run3_df], sort=False)\n",
    "\n",
    "print(all_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pots = [\n",
    "    1.42319e+20,\n",
    "    2.5413e+20,\n",
    "    2.40466e+20\n",
    "]\n",
    "\n",
    "ext_pots = [\n",
    "    2.21814e+20,\n",
    "    6.25014e+20,\n",
    "    7.4127e+20,\n",
    "]\n",
    "\n",
    "weight_cv_vals = all_df[\"weight_cv\"].to_numpy()\n",
    "weight_spline_vals = all_df[\"weight_spline\"].to_numpy()\n",
    "files = all_df[\"file\"].to_numpy()\n",
    "net_weight_vals = []\n",
    "for i in range(len(weight_cv_vals)):\n",
    "    w_cv = weight_cv_vals[i]\n",
    "    if not (0 < w_cv < 30):\n",
    "        w_cv = 1\n",
    "    \n",
    "    if files[i] == \"nu_overlay_run1\":\n",
    "        net_weight_vals.append(w_cv * weight_spline_vals[i] * data_pots[0] / nu_overlay_run1_pot)\n",
    "    elif files[i] == \"nu_overlay_run2\":\n",
    "        net_weight_vals.append(w_cv * weight_spline_vals[i] * data_pots[1] / nu_overlay_run2_pot)\n",
    "    elif files[i] == \"nu_overlay_run3\":\n",
    "        net_weight_vals.append(w_cv * weight_spline_vals[i] * data_pots[2] / nu_overlay_run3_pot)\n",
    "    \n",
    "all_df[\"net_weight\"] = net_weight_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from /exp/uboone/app/users/bbogart/wcb-uboone-bdt\n",
    "\n",
    "\"\"\"\n",
    "double LEEana::get_true_Eavail(EvalInfo& eval, PFevalInfo& pfeval, bool useThreshold, bool useMass){\n",
    "  double Eavail=0;\n",
    "  //std::cout<<pfeval.truth_Ntrack;\n",
    "  for(size_t i=0; i<pfeval.truth_Ntrack; i++){\n",
    "    int pdgcode = pfeval.truth_pdg[i];\n",
    "    int mother = pfeval.truth_mother[i];\n",
    "    //if (mother!=0) { break; }\n",
    "    if(mother==0){\n",
    "      double dx = eval.truth_vtxX-pfeval.truth_startXYZT[i][0];\n",
    "      double dy = eval.truth_vtxY-pfeval.truth_startXYZT[i][1];\n",
    "      double dz = eval.truth_vtxZ-pfeval.truth_startXYZT[i][2];\n",
    "      double vtx_diff = sqrt( dx*dx + dy*dy + dz*dz );\n",
    "      if(vtx_diff>13.25){ continue; }//catches cases with two nu\n",
    "      if( (eval.truth_nuTime*1000-pfeval.truth_startXYZT[i][3])>0.01){ continue; }//catches cases with two n\n",
    "\n",
    "      if( abs(pdgcode)==2212 && 1*(pfeval.truth_startMomentum[i][3]*1000-938.27208816)<35 && useThreshold) continue;//below threshold porton, reject if using threshold\n",
    "      else if( abs(pdgcode)==211 && pfeval.truth_startMomentum[i][3]*1000-139.57039<10 && useThreshold) continue;//below threshold pion, reject if using threshold\n",
    "      else if( abs(pdgcode)==2212 ) Eavail+=1*(pfeval.truth_startMomentum[i][3]*1000-938.27208816)+useMass*8.36; //proton KE only\n",
    "      else if(abs(pdgcode)==2112 ) continue; //primary neutron\n",
    "      else if( abs(pdgcode)==13 && abs(eval.truth_nuPdg)==14 ) continue; //primary muon from numu\n",
    "      else if( abs(pdgcode)==11 && abs(eval.truth_nuPdg)==12 ) continue; //primary e from nue\n",
    "      else if( abs(pdgcode)==15 && abs(eval.truth_nuPdg)==16 ) continue; //primary tau from nutau\n",
    "      else if( abs(pdgcode)==12 || abs(pdgcode)==14 || abs(pdgcode)==16 ) continue; //primary nu\n",
    "      else if( abs(pdgcode)>3000 && abs(pdgcode)<4000 ) continue; //strange baryon\n",
    "      else if( abs(pdgcode)==211 ) Eavail+=pfeval.truth_startMomentum[i][3]*1000-139.57039+useMass*139.57039;//pion, KE only\n",
    "      else if (abs(pdgcode)<10000 ) Eavail+=pfeval.truth_startMomentum[i][3]*1000;//everything else add all energy\n",
    "    }\n",
    "  }\n",
    "  //std::cout<<\"  \"<<Eavail<<std::endl; \n",
    "  return Eavail;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# these seem to be the default settings in Ben's configuration files\n",
    "useThreshold = False\n",
    "useMass = False\n",
    "\n",
    "truth_nuPdg_arr = all_df[\"truth_nuPdg\"].to_numpy()\n",
    "truth_Ntrack_arr = all_df[\"truth_Ntrack\"].to_numpy()\n",
    "\n",
    "truth_pdgs_arr = all_df[\"truth_pdg\"].to_numpy()\n",
    "truth_mothers_arr = all_df[\"truth_mother\"].to_numpy()\n",
    "truth_vtxXs_arr = all_df[\"truth_vtxX\"].to_numpy()\n",
    "truth_vtxYs_arr = all_df[\"truth_vtxY\"].to_numpy()\n",
    "truth_vtxZs_arr = all_df[\"truth_vtxZ\"].to_numpy()\n",
    "truth_startXYZTs_arr = all_df[\"truth_startXYZT\"].to_numpy()\n",
    "truth_startMomentums_arr = all_df[\"truth_startMomentum\"].to_numpy()\n",
    "\n",
    "E_avail_arr = []\n",
    "\n",
    "num_events = len(truth_Ntrack_arr)\n",
    "for i in tqdm(range(num_events)):\n",
    "\n",
    "    truth_nuPdg = truth_nuPdg_arr[i]\n",
    "    truth_Ntrack = truth_Ntrack_arr[i]\n",
    "\n",
    "    truth_pdgs = truth_pdgs_arr[i]\n",
    "    truth_mothers = truth_mothers_arr[i]\n",
    "    truth_vtxX = truth_vtxXs_arr[i]\n",
    "    truth_vtxY = truth_vtxYs_arr[i]\n",
    "    truth_vtxZ = truth_vtxZs_arr[i]\n",
    "    truth_startXYZTs = truth_startXYZTs_arr[i]\n",
    "    truth_startMomentums = truth_startMomentums_arr[i]\n",
    "\n",
    "    Eavail = 0\n",
    "\n",
    "    for j in range(truth_Ntrack):\n",
    "        truth_pdg = truth_pdgs[j]\n",
    "        truth_mother = truth_mothers[j]\n",
    "        truth_startXYZT = truth_startXYZTs[j]\n",
    "        truth_startMomentum = truth_startMomentums[j]\n",
    "\n",
    "        if truth_mother != 0:\n",
    "            continue\n",
    "        \n",
    "        if abs(truth_pdg) == 2212: # true proton\n",
    "            if abs(truth_startMomentum[3] * 1000 - 938.27208816) < 35 and useThreshold: # below 35 MeV, continue\n",
    "                continue\n",
    "            Eavail += truth_startMomentum[3] * 1000 - 938.27208816 + useMass * 8.36\n",
    "        \n",
    "        elif abs(truth_pdg) == 211: # true charged pion\n",
    "            if abs(truth_startMomentum[3] * 1000 - 139.57039) < 10 and useThreshold: # below 10 MeV, continue\n",
    "                continue\n",
    "            Eavail += truth_startMomentum[3] * 1000 - 139.57039 + useMass * 139.57039\n",
    "\n",
    "        elif abs(truth_pdg) == 2112: # true neutron\n",
    "            continue\n",
    "        \n",
    "        elif abs(truth_pdg) == 13 and abs(truth_nuPdg) == 14: # true muon from numu\n",
    "            continue\n",
    "\n",
    "        elif abs(truth_pdg) == 11 and abs(truth_nuPdg) == 12: # true electron from nue\n",
    "            continue\n",
    "\n",
    "        elif abs(truth_pdg) == 15 and abs(truth_nuPdg) == 16: # true tau from nutau\n",
    "            continue\n",
    "\n",
    "        elif abs(truth_pdg) == 12 or abs(truth_pdg) == 14 or abs(truth_pdg) == 16: # true neutrino\n",
    "            continue\n",
    "\n",
    "        elif 3000 < abs(truth_pdg) < 4000: # strange baryon\n",
    "            continue\n",
    "\n",
    "        elif abs(truth_pdg) < 10000: # everything else\n",
    "            Eavail += truth_startMomentum[3] * 1000\n",
    "\n",
    "    E_avail_arr.append(Eavail)\n",
    "\n",
    "all_df[\"E_avail\"] = E_avail_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
